{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UMvaXkKG0KK"
      },
      "outputs": [],
      "source": [
        "# ================================================\n",
        "# SPECKLE REDUCTION FOR SAR IMAGES USING AUTOENCODER\n",
        "# ================================================\n",
        "# This script filters SAR satellite images using a pre-trained autoencoder model.\n",
        "# Due to memory constraints, large images are processed in 512x512 patches.\n",
        "# The model must be trained separately and saved as 'model.h5'.\n",
        "# Dependencies: TensorFlow 2.15.0, Keras 2.15.0, OpenCV, Rasterio, NumPy\n",
        "# ================================================\n",
        "\n",
        "# ---- INSTALL REQUIRED DEPENDENCIES ----\n",
        "!pip install --upgrade --force-reinstall tensorflow==2.15.0\n",
        "!pip install --upgrade --force-reinstall keras==2.15.0\n",
        "!pip install rasterio\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- IMPORT LIBRARIES ----\n",
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend\n",
        "from glob import glob\n",
        "import rasterio\n",
        "from google.colab import drive\n",
        "\n",
        "# ---- MOUNT GOOGLE DRIVE ----\n",
        "# Required for loading the model and accessing SAR images\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "s_1exVmm4vNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- PREPROCESSING FUNCTION ----\n",
        "def preprocess(array):\n",
        "    \"\"\"\n",
        "    Normalizes and reshapes an array to the format expected by the autoencoder.\n",
        "\n",
        "    Args:\n",
        "        array (numpy.ndarray): Array of shape (N, 512, 512)\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Reshaped array of shape (N, 512, 512, 1), dtype float32\n",
        "    \"\"\"\n",
        "    array = array.astype(\"float32\")\n",
        "    array = np.reshape(array, (len(array), 512, 512, 1))\n",
        "    return array\n",
        "\n",
        "# ---- LOAD PRETRAINED AUTOENCODER MODEL ----\n",
        "autoencoder_loaded = keras.models.load_model('/content/drive/MyDrive/model.h5')\n",
        "\n",
        "# ---- DEFINE PROCESSING ZONES ----\n",
        "# Each zone is defined by bounding box coordinates (not directly used here)\n",
        "zones = {\n",
        "    \"CONFLUENCIA\": {\n",
        "        \"lat1\": 8.037527,\n",
        "        \"lon1\": -74.851446,\n",
        "        \"lat2\": 8.113206,\n",
        "        \"lon2\": -74.746023\n",
        "    },\n",
        "}"
      ],
      "metadata": {
        "id": "afMcCjjExM9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---- MAIN PROCESSING LOOP ----\n",
        "for zone in zones.keys():\n",
        "    # Get list of all .tif images in the VV_VISUAL folder\n",
        "    visuals = glob(f'/content/drive/MyDrive/SAR_BAJO_CAUCA/{zone}/VV_VISUAL/*.tif')\n",
        "    visuals.sort()  # Sort by filename (date)\n",
        "\n",
        "    for visual in visuals:\n",
        "        # Read the SAR image using Rasterio\n",
        "        with rasterio.open(visual) as src:\n",
        "            data = src.read()                  # Read all bands\n",
        "            image0_profile = src.profile       # Georeferencing information\n",
        "            image0_meta = src.meta             # General metadata\n",
        "\n",
        "        # Extract and normalize the first band\n",
        "        img = data[0, :, :]                    # Use the first band only\n",
        "        img = img.astype(np.single) / 255.0    # Normalize to range [0, 1]\n",
        "\n",
        "        # Create empty output image to store filtered results\n",
        "        new = np.zeros(img.shape, dtype=np.uint8)\n",
        "        h, w = new.shape\n",
        "        patch_size = 512\n",
        "\n",
        "        # ---- PROCESS IMAGE IN 512x512 PATCHES ----\n",
        "        for i in range(0, h, patch_size):\n",
        "            if i > (h - patch_size):\n",
        "                i = h - patch_size  # Prevent going out of bounds\n",
        "            for j in range(0, w, patch_size):\n",
        "                if j > (w - patch_size):\n",
        "                    j = w - patch_size\n",
        "\n",
        "                # Extract 512x512 patch from original image\n",
        "                roi = img[i:i+patch_size, j:j+patch_size]\n",
        "                val1 = cv2.resize(roi, (patch_size, patch_size))  # Ensure exact shape\n",
        "\n",
        "                # Prepare the patch for prediction\n",
        "                sfs = [val1]\n",
        "                valid = np.array(sfs, dtype=np.single)\n",
        "                valida = preprocess(valid)\n",
        "\n",
        "                # ---- APPLY AUTOENCODER FILTER ----\n",
        "                prediction = autoencoder_loaded.predict(valida)\n",
        "                imgfilt = prediction.reshape(patch_size, patch_size) * 255\n",
        "                imgfilt = imgfilt.astype(np.uint8)\n",
        "\n",
        "                # Insert filtered patch into the final image\n",
        "                new[i:i+patch_size, j:j+patch_size] = imgfilt\n",
        "\n",
        "        # ---- SAVE FILTERED IMAGE ----\n",
        "        filename = visual.split('/')[-1]  # Extract the filename\n",
        "        new_profile = image0_profile.copy()\n",
        "        new_profile.update(count=1, dtype=rasterio.uint8)  # Update for single-band uint8 image\n",
        "\n",
        "        # Output file path\n",
        "        output_path = f'/content/drive/MyDrive/{zone}/VV_VISUAL_FILT/' + filename\n",
        "\n",
        "        # Write the filtered image using Rasterio\n",
        "        with rasterio.open(output_path, 'w', **new_profile) as dst:\n",
        "            dst.write(new, 1)  # Write to the first band\n",
        "\n",
        "        print(f'{zone} {filename} successfully filtered and saved!')"
      ],
      "metadata": {
        "id": "14JcVCA8xZ3E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}